{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "next-word-inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR1A4P9ERZPr"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/models/Next Word Prediction/next-word.h5\" \"./\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFVTpum9TDG6"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqz2NcgLSHk_"
      },
      "source": [
        "### Building the inference model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gthSrTeSEl7"
      },
      "source": [
        "model_weights = \"/content/next-word.h5\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMPMNP_SXnK"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                         batch_input_shape=[batch_size, None]),\n",
        "                               tf.keras.layers.GRU(rnn_units,\n",
        "                                                   return_sequences=True,\n",
        "                                                   stateful=True),\n",
        "                               tf.keras.layers.Dense(vocab_size)\n",
        "])\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGCDxQugSi_M"
      },
      "source": [
        "chars = sorted(set(\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'''/\\|_@#$%ˆ&*˜'+-=()[]{}' ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))\n",
        "chars = list(chars)\n",
        "EOS = '<EOS>'\n",
        "UNK = \"<UNK>\"\n",
        "PAD = \"<PAD>\"\n",
        "chars.append(UNK)\n",
        "chars.append(EOS)\n",
        "chars.insert(0, PAD)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKLfYN7S8yX"
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(chars)}\n",
        "idx2char = np.array(chars)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNSR2gBYS_KU"
      },
      "source": [
        "def char_idx(c):\n",
        "    if c in chars:\n",
        "        return char2idx[c]\n",
        "    return char2idx[UNK]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjpQf6YoTLTi"
      },
      "source": [
        "# Hyperparameters\n",
        "vocab_size = len(chars)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "BATCH_SIZE=1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diSTCWaTTRwj"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve9mpmyIThi9"
      },
      "source": [
        "model.load_weights(model_weights)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnGIYZwKTmpg"
      },
      "source": [
        "def generate_text(model, start_string, temperature=0.4, num_generate=30):\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  for i in range(num_generate):\n",
        "    predictions = model.predict(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "    if predicted_id == char2idx[\"<EOS>\"]:\n",
        "      break\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "  return (''.join(text_generated))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lhmUsLCapUR"
      },
      "source": [
        "def get_text(text):\n",
        "  gen_txt = generate_text(model, test_text)\n",
        "  gen_txt = gen_txt.lower()\n",
        "  gen_txt = gen_txt.strip()\n",
        "  gen_txt = gen_txt.split()\n",
        "  return gen_txt[:3]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz6wFSttaUtP",
        "outputId": "fdb10aff-8787-4f33-aaaf-4d585eb942d4"
      },
      "source": [
        "text1 = \"I want to\"\n",
        "get_text(text1)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['save', 'lives']"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8mRNob7WV6S",
        "outputId": "09dd42ba-f37e-4c69-872d-09816fb806c2"
      },
      "source": [
        "text2= \"I like\"\n",
        "get_text(text2)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['experience', 'the', 'foreclosure']"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6cP55jJW9Q9",
        "outputId": "5758733f-e7cb-49c6-ca7c-cefda4e52297"
      },
      "source": [
        "text3= \"He likes to \"\n",
        "get_text(text3)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['be', 'healthy']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzH9cvgbaOjF"
      },
      "source": [
        ""
      ],
      "execution_count": 141,
      "outputs": []
    }
  ]
}